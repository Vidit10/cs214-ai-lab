{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9828c2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering, DBSCAN\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "# Load MNIST subset\n",
    "mnist = load_digits()\n",
    "data = mnist.data\n",
    "labels = mnist.target\n",
    "\n",
    "# Filter for digits 0-4\n",
    "filtered_indices = np.where(labels < 5)\n",
    "data = data[filtered_indices]\n",
    "labels = labels[filtered_indices]\n",
    "\n",
    "# Normalize the dataset\n",
    "scaler = StandardScaler()\n",
    "data_normalized = scaler.fit_transform(data)\n",
    "\n",
    "# Apply PCA to reduce to 2D\n",
    "pca = PCA(n_components=2)\n",
    "data_2D = pca.fit_transform(data_normalized)\n",
    "\n",
    "# Create DataFrame for the reduced data\n",
    "mnist_dataset_2D = pd.DataFrame(data_2D, columns=['PC1', 'PC2'])\n",
    "mnist_dataset_2D['label'] = labels\n",
    "\n",
    "# Visualize the reduced data colored by actual digits\n",
    "plt.figure(figsize=(10, 8))\n",
    "for digit in range(5):\n",
    "    subset = mnist_dataset_2D[mnist_dataset_2D['label'] == digit]\n",
    "    plt.scatter(subset['PC1'], subset['PC2'], label=f'Digit {digit}')\n",
    "plt.title('MNIST Dataset Reduced to 2D')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Extract features and labels\n",
    "X = mnist_dataset_2D[['PC1', 'PC2']].values\n",
    "y_true = mnist_dataset_2D['label'].values\n",
    "\n",
    "# Define purity score function\n",
    "def purity_score(y_true, y_pred):\n",
    "    contingency_matrix = pd.crosstab(y_true, y_pred)\n",
    "    return np.sum(np.amax(contingency_matrix.values, axis=0)) / np.sum(contingency_matrix.values)\n",
    "\n",
    "# Part 2: Hierarchical Clustering\n",
    "# Apply Agglomerative Hierarchical Clustering with n_clusters=5 and linkage='ward'\n",
    "hierarchical_clustering = AgglomerativeClustering(n_clusters=5, linkage='ward')\n",
    "cluster_labels = hierarchical_clustering.fit_predict(X)\n",
    "\n",
    "# Visualize the clusters\n",
    "plt.figure(figsize=(10, 8))\n",
    "for cluster in range(5):\n",
    "    subset = X[cluster_labels == cluster]\n",
    "    plt.scatter(subset[:, 0], subset[:, 1], label=f'Cluster {cluster}')\n",
    "plt.title('Hierarchical Clustering with Ward Linkage')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate purity score\n",
    "ward_purity = purity_score(y_true, cluster_labels)\n",
    "print(f'Purity Score for Ward Linkage: {ward_purity:.4f}')\n",
    "\n",
    "# Try different linkage methods\n",
    "linkage_methods = ['single', 'complete', 'average', 'ward']\n",
    "purity_scores = {}\n",
    "\n",
    "for method in linkage_methods:\n",
    "    clustering = AgglomerativeClustering(n_clusters=5, linkage=method)\n",
    "    labels = clustering.fit_predict(X)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for cluster in range(5):\n",
    "        subset = X[labels == cluster]\n",
    "        plt.scatter(subset[:, 0], subset[:, 1], label=f'Cluster {cluster}')\n",
    "    plt.title(f'Hierarchical Clustering with {method.capitalize()} Linkage')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    method_purity = purity_score(y_true, labels)\n",
    "    purity_scores[method] = method_purity\n",
    "    print(f'Purity Score for {method.capitalize()} Linkage: {method_purity:.4f}')\n",
    "\n",
    "# Find best linkage method\n",
    "best_linkage = max(purity_scores, key=purity_scores.get)\n",
    "print(f'Best linkage method: {best_linkage} with purity score: {purity_scores[best_linkage]:.4f}')\n",
    "\n",
    "# Generate dendrogram\n",
    "plt.figure(figsize=(12, 8))\n",
    "linked = linkage(X, method='ward')\n",
    "dendrogram(linked)\n",
    "plt.title('Dendrogram for Ward Linkage')\n",
    "plt.axhline(y=10, color='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "# Apply clustering with optimal number of clusters from dendrogram (using threshold=10)\n",
    "optimal_clustering = AgglomerativeClustering(n_clusters=None, linkage=best_linkage, distance_threshold=10)\n",
    "optimal_labels = optimal_clustering.fit_predict(X)\n",
    "n_clusters = len(np.unique(optimal_labels))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for cluster in range(n_clusters):\n",
    "    subset = X[optimal_labels == cluster]\n",
    "    plt.scatter(subset[:, 0], subset[:, 1], label=f'Cluster {cluster}')\n",
    "plt.title(f'Hierarchical Clustering with Optimal Clusters ({n_clusters})')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Find most frequent digit in each cluster\n",
    "for cluster in range(n_clusters):\n",
    "    cluster_indices = np.where(optimal_labels == cluster)[0]\n",
    "    cluster_digits = y_true[cluster_indices]\n",
    "    digit_counts = np.bincount(cluster_digits)\n",
    "    most_frequent = np.argmax(digit_counts)\n",
    "    print(f'Cluster {cluster}: Most frequent digit is {most_frequent}')\n",
    "\n",
    "# Part 3: DBSCAN Clustering\n",
    "# Apply DBSCAN with default parameters\n",
    "dbscan = DBSCAN()\n",
    "dbscan_labels = dbscan.fit_predict(X)\n",
    "n_clusters_dbscan = len(np.unique(dbscan_labels[dbscan_labels >= 0]))\n",
    "n_noise = np.sum(dbscan_labels == -1)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Plot noise points\n",
    "noise = X[dbscan_labels == -1]\n",
    "plt.scatter(noise[:, 0], noise[:, 1], color='black', label='Noise', alpha=0.5)\n",
    "\n",
    "# Plot clusters\n",
    "for cluster in range(n_clusters_dbscan):\n",
    "    subset = X[dbscan_labels == cluster]\n",
    "    plt.scatter(subset[:, 0], subset[:, 1], label=f'Cluster {cluster}')\n",
    "    \n",
    "plt.title(f'DBSCAN Clustering (Clusters: {n_clusters_dbscan}, Noise: {n_noise})')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate purity score for DBSCAN (excluding noise points)\n",
    "valid_indices = dbscan_labels != -1\n",
    "if np.any(valid_indices):\n",
    "    dbscan_purity = purity_score(y_true[valid_indices], dbscan_labels[valid_indices])\n",
    "    print(f'DBSCAN Purity Score (excluding noise): {dbscan_purity:.4f}')\n",
    "\n",
    "# Try different eps and min_samples values\n",
    "eps_values = [0.5, 1, 5]\n",
    "min_samples_values = [1, 5, 10]\n",
    "dbscan_results = {}\n",
    "\n",
    "for eps in eps_values:\n",
    "    for min_samples in min_samples_values:\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels = dbscan.fit_predict(X)\n",
    "        n_clusters = len(np.unique(labels[labels >= 0]))\n",
    "        n_noise = np.sum(labels == -1)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        # Plot noise points\n",
    "        noise = X[labels == -1]\n",
    "        plt.scatter(noise[:, 0], noise[:, 1], color='black', label='Noise', alpha=0.5)\n",
    "        \n",
    "        # Plot clusters\n",
    "        for cluster in range(n_clusters):\n",
    "            subset = X[labels == cluster]\n",
    "            plt.scatter(subset[:, 0], subset[:, 1], label=f'Cluster {cluster}')\n",
    "            \n",
    "        plt.title(f'DBSCAN (eps={eps}, min_samples={min_samples}, Clusters: {n_clusters}, Noise: {n_noise})')\n",
    "        plt.xlabel('Principal Component 1')\n",
    "        plt.ylabel('Principal Component 2')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "        # Calculate purity score (excluding noise points)\n",
    "        valid_indices = labels != -1\n",
    "        if np.any(valid_indices):\n",
    "            params_purity = purity_score(y_true[valid_indices], labels[valid_indices])\n",
    "            dbscan_results[(eps, min_samples)] = params_purity\n",
    "            print(f'DBSCAN Purity (eps={eps}, min_samples={min_samples}): {params_purity:.4f}')\n",
    "            \n",
    "            # Find most frequent digit in each cluster\n",
    "            for cluster in range(n_clusters):\n",
    "                cluster_indices = np.where(labels == cluster)[0]\n",
    "                cluster_digits = y_true[cluster_indices]\n",
    "                digit_counts = np.bincount(cluster_digits)\n",
    "                most_frequent = np.argmax(digit_counts)\n",
    "                print(f'  Cluster {cluster}: Most frequent digit is {most_frequent}')\n",
    "\n",
    "# Find best DBSCAN parameters\n",
    "if dbscan_results:\n",
    "    best_params = max(dbscan_results, key=dbscan_results.get)\n",
    "    print(f'Best DBSCAN parameters: eps={best_params[0]}, min_samples={best_params[1]} with purity: {dbscan_results[best_params]:.4f}')\n",
    "\n",
    "# Compare different distance metrics for DBSCAN\n",
    "metrics = ['euclidean', 'manhattan', 'cosine']\n",
    "best_eps, best_min_samples = best_params if dbscan_results else (0.5, 5)\n",
    "\n",
    "for metric in metrics:\n",
    "    dbscan = DBSCAN(eps=best_eps, min_samples=best_min_samples, metric=metric)\n",
    "    labels = dbscan.fit_predict(X)\n",
    "    n_clusters = len(np.unique(labels[labels >= 0]))\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    # Plot noise points\n",
    "    noise = X[labels == -1]\n",
    "    plt.scatter(noise[:, 0], noise[:, 1], color='black', label='Noise', alpha=0.5)\n",
    "    \n",
    "    # Plot clusters\n",
    "    for cluster in range(n_clusters):\n",
    "        subset = X[labels == cluster]\n",
    "        plt.scatter(subset[:, 0], subset[:, 1], label=f'Cluster {cluster}')\n",
    "        \n",
    "    plt.title(f'DBSCAN with {metric} distance metric (Clusters: {n_clusters})')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate purity score (excluding noise points)\n",
    "    valid_indices = labels != -1\n",
    "    if np.any(valid_indices):\n",
    "        metric_purity = purity_score(y_true[valid_indices], labels[valid_indices])\n",
    "        print(f'DBSCAN Purity with {metric} metric: {metric_purity:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
