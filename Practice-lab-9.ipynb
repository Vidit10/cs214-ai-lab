{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Read CSV (make sure path is correct)\n",
    "df = pd.read_csv(\"Concrete_Data.csv\")\n",
    "\n",
    "# Define the target column\n",
    "target_col = \"Concrete_compressive_strength \"\n",
    "\n",
    "# Double-check that target_col is present\n",
    "if target_col not in df.columns:\n",
    "    # Try with space at the end if needed\n",
    "    target_col = \"Concrete_compressive_strength \"\n",
    "    if target_col not in df.columns:\n",
    "        raise KeyError(f\"Target column not found. Please verify your CSV column names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Split into Train (60%), Validation (20%), Test (20%)\n",
    "df_temp, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train, df_val = train_test_split(df_temp, test_size=0.25, random_state=42)\n",
    "\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_val.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 3) Fill missing values with median from train (if any)\n",
    "for col in df_train.columns:\n",
    "    median_val = df_train[col].median()\n",
    "    df_train[col] = df_train[col].fillna(median_val)\n",
    "    df_val[col] = df_val[col].fillna(median_val)\n",
    "    df_test[col] = df_test[col].fillna(median_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Find top 2 correlated features with the target on the TRAIN set\n",
    "corrs = []\n",
    "for col in df_train.columns:\n",
    "    if col != target_col:\n",
    "        corrs.append((col, df_train[col].corr(df_train[target_col])))\n",
    "\n",
    "# Sort by absolute correlation in descending order\n",
    "corrs_sorted = sorted(corrs, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Extract top 2\n",
    "feature1, corr1 = corrs_sorted[0]\n",
    "feature2, corr2 = corrs_sorted[1]\n",
    "print(f\"Top 2 features: {feature1} (corr: {corr1:.3f}), {feature2} (corr: {corr2:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# PROBLEM STATEMENT 1: TOP-2 FEATURES\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Multiple Linear Regression (Top 2 Features)\n",
    "X_train = df_train[[feature1, feature2]]\n",
    "y_train = df_train[target_col]\n",
    "model = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RMSE for train, validation, and test\n",
    "y_train_pred = model.predict(X_train)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "X_val = df_val[[feature1, feature2]]\n",
    "y_val = df_val[target_col]\n",
    "y_val_pred = model.predict(X_val)\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "X_test = df_test[[feature1, feature2]]\n",
    "y_test = df_test[target_col]\n",
    "y_test_pred = model.predict(X_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the best-fit plane on the TRAINING data\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(X_train[feature1], X_train[feature2], y_train, alpha=0.7)\n",
    "\n",
    "# Create a mesh for plotting the plane\n",
    "x_surf = np.linspace(X_train[feature1].min(), X_train[feature1].max(), 20)\n",
    "y_surf = np.linspace(X_train[feature2].min(), X_train[feature2].max(), 20)\n",
    "x_surf, y_surf = np.meshgrid(x_surf, y_surf)\n",
    "\n",
    "z_surf = model.predict(np.column_stack((x_surf.ravel(), y_surf.ravel())))\n",
    "z_surf = z_surf.reshape(x_surf.shape)\n",
    "\n",
    "ax.plot_surface(x_surf, y_surf, z_surf, alpha=0.3)\n",
    "ax.set_xlabel(feature1)\n",
    "ax.set_ylabel(feature2)\n",
    "ax.set_zlabel(target_col)\n",
    "ax.set_title(\"Best-Fit Plane (Training Data)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Actual vs. Predicted on TEST data\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.7)\n",
    "plt.xlabel(\"Actual Strength (MPa)\")\n",
    "plt.ylabel(\"Predicted Strength (MPa)\")\n",
    "plt.title(\"Actual vs Predicted (Test Data)\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Linear Regression with Top 2 Features:\")\n",
    "print(f\"Train RMSE: {rmse_train:.3f}\")\n",
    "print(f\"Validation RMSE: {rmse_val:.3f}\")\n",
    "print(f\"Test RMSE: {rmse_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Polynomial Regression (Top 2 Features)\n",
    "degrees = [2, 3, 4, 5]\n",
    "train_rmse_poly = []\n",
    "val_rmse_poly = []\n",
    "models_poly = []\n",
    "\n",
    "for d in degrees:\n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree=d)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_val_poly = poly.transform(X_val)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "    \n",
    "    # Train model\n",
    "    model_poly = LinearRegression().fit(X_train_poly, y_train)\n",
    "    models_poly.append((poly, model_poly))\n",
    "    \n",
    "    # Compute RMSE\n",
    "    y_train_pred_poly = model_poly.predict(X_train_poly)\n",
    "    y_val_pred_poly = model_poly.predict(X_val_poly)\n",
    "    \n",
    "    rmse_train_poly = np.sqrt(mean_squared_error(y_train, y_train_pred_poly))\n",
    "    rmse_val_poly = np.sqrt(mean_squared_error(y_val, y_val_pred_poly))\n",
    "    \n",
    "    train_rmse_poly.append(rmse_train_poly)\n",
    "    val_rmse_poly.append(rmse_val_poly)\n",
    "    \n",
    "    # Plot best-fit surface for each degree\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(X_train[feature1], X_train[feature2], y_train, alpha=0.7)\n",
    "    \n",
    "    # Create a mesh grid for the surface\n",
    "    x_surf = np.linspace(X_train[feature1].min(), X_train[feature1].max(), 20)\n",
    "    y_surf = np.linspace(X_train[feature2].min(), X_train[feature2].max(), 20)\n",
    "    x_surf, y_surf = np.meshgrid(x_surf, y_surf)\n",
    "    \n",
    "    # Predict on the mesh grid\n",
    "    mesh_points = np.column_stack((x_surf.ravel(), y_surf.ravel()))\n",
    "    mesh_points_poly = poly.transform(mesh_points)\n",
    "    z_surf = model_poly.predict(mesh_points_poly).reshape(x_surf.shape)\n",
    "    \n",
    "    ax.plot_surface(x_surf, y_surf, z_surf, alpha=0.3)\n",
    "    ax.set_xlabel(feature1)\n",
    "    ax.set_ylabel(feature2)\n",
    "    ax.set_zlabel(target_col)\n",
    "    ax.set_title(f\"Polynomial Regression (Degree {d}) - Training Data\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best polynomial degree based on validation RMSE\n",
    "best_degree_idx = np.argmin(val_rmse_poly)\n",
    "best_degree = degrees[best_degree_idx]\n",
    "best_poly, best_model_poly = models_poly[best_degree_idx]\n",
    "\n",
    "# Evaluate on test set\n",
    "X_test_poly = best_poly.transform(X_test)\n",
    "y_test_pred_poly = best_model_poly.predict(X_test_poly)\n",
    "rmse_test_poly = np.sqrt(mean_squared_error(y_test, y_test_pred_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar graph: RMSE vs Polynomial Degree\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(degrees, val_rmse_poly, color='skyblue')\n",
    "plt.xlabel('Polynomial Degree')\n",
    "plt.ylabel('Validation RMSE')\n",
    "plt.title('Validation RMSE vs Polynomial Degree')\n",
    "plt.xticks(degrees)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for best polynomial model\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_test_pred_poly, alpha=0.7)\n",
    "plt.xlabel(\"Actual Strength (MPa)\")\n",
    "plt.ylabel(\"Predicted Strength (MPa)\")\n",
    "plt.title(f\"Polynomial Regression (Degree {best_degree}) - Test Data\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nPolynomial Regression with Top 2 Features:\")\n",
    "print(f\"Best Polynomial Degree: {best_degree}\")\n",
    "print(f\"Test RMSE: {rmse_test_poly:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Neural Network (Top 2 Features)\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train.values)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values).view(-1, 1)\n",
    "X_val_tensor = torch.FloatTensor(X_val.values)\n",
    "y_val_tensor = torch.FloatTensor(y_val.values).view(-1, 1)\n",
    "X_test_tensor = torch.FloatTensor(X_test.values)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the NeuralNet class if not already defined\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size=2, hidden_dim=32):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_dim),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dims = [8, 16, 32, 64]\n",
    "val_rmse_nn = []\n",
    "models_nn = []\n",
    "train_losses_list = []\n",
    "\n",
    "input_size = 2  # For top 2 features\n",
    "\n",
    "for hidden_dim in hidden_dims:\n",
    "    model_nn = NeuralNet(input_size=input_size, hidden_dim=hidden_dim)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model_nn.parameters(), lr=0.01)\n",
    "    \n",
    "    # Training loop\n",
    "    epochs = 1000\n",
    "    train_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model_nn.train()\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model_nn(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Record training loss\n",
    "        model_nn.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model_nn(X_train_tensor)\n",
    "            train_loss = criterion(outputs, y_train_tensor).item()\n",
    "            train_losses.append(train_loss)\n",
    "    \n",
    "    train_losses_list.append(train_losses)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    model_nn.eval()\n",
    "    with torch.no_grad():\n",
    "        val_pred = model_nn(X_val_tensor)\n",
    "        val_rmse = np.sqrt(mean_squared_error(y_val_tensor.numpy(), val_pred.numpy()))\n",
    "        val_rmse_nn.append(val_rmse)\n",
    "    \n",
    "    models_nn.append(model_nn)\n",
    "    \n",
    "    # Plot best-fit surface\n",
    "    model_nn.eval()\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(X_train[feature1], X_train[feature2], y_train, alpha=0.7)\n",
    "    \n",
    "    # Create a mesh grid for the surface\n",
    "    x_surf = np.linspace(X_train[feature1].min(), X_train[feature1].max(), 20)\n",
    "    y_surf = np.linspace(X_train[feature2].min(), X_train[feature2].max(), 20)\n",
    "    x_surf, y_surf = np.meshgrid(x_surf, y_surf)\n",
    "    \n",
    "    # Predict on the mesh grid\n",
    "    mesh_points = np.column_stack((x_surf.ravel(), y_surf.ravel()))\n",
    "    with torch.no_grad():\n",
    "        mesh_tensor = torch.FloatTensor(mesh_points)\n",
    "        z_surf = model_nn(mesh_tensor).numpy().reshape(x_surf.shape)\n",
    "    \n",
    "    ax.plot_surface(x_surf, y_surf, z_surf, alpha=0.3)\n",
    "    ax.set_xlabel(feature1)\n",
    "    ax.set_ylabel(feature2)\n",
    "    ax.set_zlabel(target_col)\n",
    "    ax.set_title(f\"Neural Network (Hidden Dim: {hidden_dim}) - Training Data\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best neural network based on validation RMSE\n",
    "best_nn_idx = np.argmin(val_rmse_nn)\n",
    "best_hidden_dim = hidden_dims[best_nn_idx]\n",
    "best_model_nn = models_nn[best_nn_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "best_model_nn.eval()\n",
    "with torch.no_grad():\n",
    "    test_pred_nn = best_model_nn(X_test_tensor)\n",
    "    rmse_test_nn = np.sqrt(mean_squared_error(y_test_tensor.numpy(), test_pred_nn.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss vs epochs for best model\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses_list[best_nn_idx])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title(f'Training Loss vs Epochs (Hidden Dim: {best_hidden_dim})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for best neural network\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test.values, test_pred_nn.numpy(), alpha=0.7)\n",
    "plt.xlabel(\"Actual Strength (MPa)\")\n",
    "plt.ylabel(\"Predicted Strength (MPa)\")\n",
    "plt.title(f\"Neural Network (Hidden Dim: {best_hidden_dim}) - Test Data\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nNeural Network with Top 2 Features:\")\n",
    "print(f\"Best Hidden Dimension: {best_hidden_dim}\")\n",
    "print(f\"Test RMSE: {rmse_test_nn:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
