{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Preprocessing and Dimensionality Reduction\n",
    "# 1a. Load the MNIST subset and consider only digits 0-4\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "# Filter to keep only digits 0-4\n",
    "mask = y < 5\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "# 1b. Normalize the dataset\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA to reduce dimensions to 2D\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# 1c. Save this 2D dataset as mnist_dataset_2D\n",
    "mnist_dataset_2D = X_pca\n",
    "\n",
    "# Visualize the 2D dataset\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(mnist_dataset_2D[:, 0], mnist_dataset_2D[:, 1], c=y, cmap='tab10', alpha=0.6)\n",
    "plt.colorbar(scatter, label=\"Digit Label\")\n",
    "plt.title('2D Visualization of MNIST Dataset (Digits 0-4)')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. K-Means Clustering and Comparison\n",
    "\n",
    "# 2b. Perform K-Means with k=5\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(mnist_dataset_2D)\n",
    "kmeans_labels = kmeans.labels_\n",
    "\n",
    "# Visualize K-Means Clustering with k=5\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(mnist_dataset_2D[:, 0], mnist_dataset_2D[:, 1], c=kmeans_labels, cmap='viridis', alpha=0.6)\n",
    "plt.colorbar(scatter, label=\"Cluster Label\")\n",
    "plt.title('K-Means Clustering on MNIST (k=5)')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.show()\n",
    "\n",
    "# 2c. K-Means Clustering for different values of k (2, 3, 4, 5)\n",
    "k_values = [2, 3, 4, 5]\n",
    "inertia_values = []\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, max_iter=50)\n",
    "    kmeans.fit(mnist_dataset_2D)\n",
    "    labels = kmeans.labels_\n",
    "    inertia_values.append(kmeans.inertia_)\n",
    "    \n",
    "    # Visualize clustering for each k\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(mnist_dataset_2D[:, 0], mnist_dataset_2D[:, 1], c=labels, cmap='viridis', alpha=0.6)\n",
    "    plt.colorbar(scatter, label=\"Cluster Label\")\n",
    "    plt.title(f'K-Means Clustering on MNIST (k={k})')\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.show()\n",
    "\n",
    "# 2d. Compute and report the sum of squared distances (inertia)\n",
    "print(\"Sum of squared distances (inertia) for different k values:\")\n",
    "for k, inertia in zip(k_values, inertia_values):\n",
    "    print(f\"k={k}, Inertia={inertia:.2f}\")\n",
    "\n",
    "# 2e. Plot the Elbow Curve and identify the optimal k\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, inertia_values, 'o-', linewidth=2, markersize=8)\n",
    "plt.title('Elbow Curve for K-Means Clustering')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia (Sum of Squared Distances)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Perform clustering with the optimal k (Let's say it's 4 based on the elbow curve)\n",
    "optimal_k = 4  # This should be determined by analyzing the elbow curve\n",
    "kmeans_optimal = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "kmeans_optimal.fit(mnist_dataset_2D)\n",
    "optimal_labels = kmeans_optimal.labels_\n",
    "\n",
    "# Visualize clustering with optimal k\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(mnist_dataset_2D[:, 0], mnist_dataset_2D[:, 1], c=optimal_labels, cmap='viridis', alpha=0.6)\n",
    "plt.colorbar(scatter, label=\"Cluster Label\")\n",
    "plt.title(f'K-Means Clustering on MNIST with Optimal k={optimal_k}')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Visualizing Clusters in K-Means\n",
    "\n",
    "# 3a. Extract and display sample images from each cluster\n",
    "plt.figure(figsize=(15, 10))\n",
    "num_samples_per_cluster = 5\n",
    "\n",
    "for cluster_idx in range(optimal_k):\n",
    "    cluster_samples = np.where(optimal_labels == cluster_idx)[0]\n",
    "    \n",
    "    # Take a few samples from this cluster\n",
    "    if len(cluster_samples) >= num_samples_per_cluster:\n",
    "        sample_indices = np.random.choice(cluster_samples, num_samples_per_cluster, replace=False)\n",
    "        \n",
    "        for i, idx in enumerate(sample_indices):\n",
    "            plt.subplot(optimal_k, num_samples_per_cluster, cluster_idx * num_samples_per_cluster + i + 1)\n",
    "            plt.imshow(digits.images[mask][idx], cmap='binary')\n",
    "            plt.title(f\"Cluster {cluster_idx}\\nTrue: {y[idx]}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3b. Find and display the most frequent digit in optimal clusters\n",
    "print(\"\\nCluster analysis for K-Means with optimal k:\")\n",
    "for cluster_idx in range(optimal_k):\n",
    "    cluster_samples = np.where(optimal_labels == cluster_idx)[0]\n",
    "    cluster_labels = y[cluster_samples]\n",
    "    \n",
    "    # Count the frequency of each digit in this cluster\n",
    "    counter = Counter(cluster_labels)\n",
    "    most_common_digit, count = counter.most_common(1)[0]\n",
    "    purity = count / len(cluster_samples) * 100\n",
    "    \n",
    "    print(f\"Cluster {cluster_idx}:\")\n",
    "    print(f\"  Most frequent digit: {most_common_digit}\")\n",
    "    print(f\"  Cluster purity: {purity:.2f}%\")\n",
    "    print(f\"  Digit distribution: {dict(counter)}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. K-Medoid Clustering\n",
    "\n",
    "# 4b. Perform K-Medoid with k=5\n",
    "kmedoids = KMedoids(n_clusters=5, random_state=42, max_iter=100)\n",
    "kmedoids.fit(mnist_dataset_2D)\n",
    "kmedoids_labels = kmedoids.labels_\n",
    "\n",
    "# Visualize K-Medoid Clustering with k=5\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(mnist_dataset_2D[:, 0], mnist_dataset_2D[:, 1], c=kmedoids_labels, cmap='tab10', alpha=0.6)\n",
    "plt.colorbar(scatter, label=\"Cluster Label\")\n",
    "plt.title('K-Medoid Clustering on MNIST (k=5)')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.show()\n",
    "\n",
    "# 4c. K-Medoid Clustering for different values of k (2, 3, 4, 5)\n",
    "k_values = [2, 3, 4, 5]\n",
    "kmedoids_inertia_values = []\n",
    "\n",
    "for k in k_values:\n",
    "    kmedoids = KMedoids(n_clusters=k, random_state=42, max_iter=50)\n",
    "    kmedoids.fit(mnist_dataset_2D)\n",
    "    labels = kmedoids.labels_\n",
    "    \n",
    "    # Calculate inertia (sum of distances to medoids)\n",
    "    inertia = 0\n",
    "    for i, label in enumerate(labels):\n",
    "        medoid = kmedoids.cluster_centers_[label]\n",
    "        inertia += np.sum((mnist_dataset_2D[i] - medoid) ** 2)\n",
    "    \n",
    "    kmedoids_inertia_values.append(inertia)\n",
    "    \n",
    "    # Visualize clustering for each k\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(mnist_dataset_2D[:, 0], mnist_dataset_2D[:, 1], c=labels, cmap='tab10', alpha=0.6)\n",
    "    plt.colorbar(scatter, label=\"Cluster Label\")\n",
    "    plt.title(f'K-Medoid Clustering on MNIST (k={k})')\n",
    "    plt.xlabel('PCA Component 1')\n",
    "    plt.ylabel('PCA Component 2')\n",
    "    plt.show()\n",
    "\n",
    "# 4d. Compute and report the sum of squared distances\n",
    "print(\"\\nSum of squared distances for K-Medoid with different k values:\")\n",
    "for k, inertia in zip(k_values, kmedoids_inertia_values):\n",
    "    print(f\"k={k}, Sum of Squared Distances={inertia:.2f}\")\n",
    "\n",
    "# 4e. Plot the Elbow Curve for K-Medoid and identify the optimal k\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, kmedoids_inertia_values, 'o-', linewidth=2, markersize=8)\n",
    "plt.title('Elbow Curve for K-Medoid Clustering')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Sum of Squared Distances')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Perform K-Medoid clustering with the optimal k\n",
    "kmedoid_optimal_k = 4  # Determine based on elbow curve analysis\n",
    "kmedoids_optimal = KMedoids(n_clusters=kmedoid_optimal_k, random_state=42)\n",
    "kmedoids_optimal.fit(mnist_dataset_2D)\n",
    "kmedoid_optimal_labels = kmedoids_optimal.labels_\n",
    "\n",
    "# Visualize K-Medoid clustering with optimal k\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(mnist_dataset_2D[:, 0], mnist_dataset_2D[:, 1], c=kmedoid_optimal_labels, cmap='tab10', alpha=0.6)\n",
    "plt.colorbar(scatter, label=\"Cluster Label\")\n",
    "plt.title(f'K-Medoid Clustering on MNIST with Optimal k={kmedoid_optimal_k}')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.show()\n",
    "\n",
    "# 4f. Find and display the most frequent digit in optimal K-Medoid clusters\n",
    "print(\"\\nCluster analysis for K-Medoid with optimal k:\")\n",
    "for cluster_idx in range(kmedoid_optimal_k):\n",
    "    cluster_samples = np.where(kmedoid_optimal_labels == cluster_idx)[0]\n",
    "    cluster_labels = y[cluster_samples]\n",
    "    \n",
    "    # Count the frequency of each digit in this cluster\n",
    "    counter = Counter(cluster_labels)\n",
    "    most_common_digit, count = counter.most_common(1)[0]\n",
    "    purity = count / len(cluster_samples) * 100\n",
    "    \n",
    "    print(f\"Cluster {cluster_idx}:\")\n",
    "    print(f\"  Most frequent digit: {most_common_digit}\")\n",
    "    print(f\"  Cluster purity: {purity:.2f}%\")\n",
    "    print(f\"  Digit distribution: {dict(counter)}\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
