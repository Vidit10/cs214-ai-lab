{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from statsmodels.tsa.ar_model import AutoReg as AR\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error\n",
    "import seaborn as sns\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load and prepare the pollution dataset.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.set_index('Date', inplace=True)\n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "df = load_data('Pollution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(file_path):\n",
    "    \"\"\"Load and prepare the pollution dataset.\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df.set_index('Date', inplace=True)\n",
    "    return df\n",
    "\n",
    "def plot_time_series(df):\n",
    "    \"\"\"Create a line plot of PM2.5 values over time.\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Convert to numpy array before plotting\n",
    "    plt.plot(df.index.to_numpy(), df['pm2.5'].to_numpy())\n",
    "    plt.title('Pollution over Time')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('PM2.5')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Observations from the time series plot:\")\n",
    "    print(\"1. The data shows high variability with significant peaks and troughs.\")\n",
    "    print(\"2. There appears to be some seasonality in the pollution levels.\")\n",
    "    print(\"3. Some extreme values (spikes) can be observed throughout the time period.\")\n",
    "    print(\"4. There are periods with missing data (shown as gaps or zeros in the plot).\")\n",
    "\n",
    "def compute_lag_correlation(df):\n",
    "    \"\"\"Generate lagged time sequence and compute Pearson correlation.\"\"\"\n",
    "    # Create lagged series\n",
    "    df['lag_1'] = df['pm2.5'].shift(1)\n",
    "    \n",
    "    # Drop NaN values\n",
    "    df_clean = df.dropna()\n",
    "    \n",
    "    # Compute Pearson correlation\n",
    "    correlation, p_value = pearsonr(df_clean['pm2.5'], df_clean['lag_1'])\n",
    "    \n",
    "    print(f\"Pearson correlation coefficient for one-day lag: {correlation:.4f}\")\n",
    "    print(f\"P-value: {p_value:.10f}\")\n",
    "    \n",
    "    return df_clean, correlation\n",
    "\n",
    "def plot_lag_scatter(df_clean):\n",
    "    \"\"\"Create scatter plot between original and lagged values.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Convert to numpy arrays before plotting\n",
    "    plt.scatter(df_clean['lag_1'].to_numpy(), df_clean['pm2.5'].to_numpy(), alpha=0.5, color='blue')\n",
    "    plt.title('Scatter Plot: Current vs. Lagged PM2.5 Values')\n",
    "    plt.xlabel('PM2.5 at t-1')\n",
    "    plt.ylabel('PM2.5 at t')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Add a line of best fit\n",
    "    z = np.polyfit(df_clean['lag_1'].to_numpy(), df_clean['pm2.5'].to_numpy(), 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(df_clean['lag_1'].to_numpy(), p(df_clean['lag_1'].to_numpy()), \"r--\", alpha=0.8)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Inference from scatter plot:\")\n",
    "    print(\"1. There is a strong positive correlation between current and lagged PM2.5 values.\")\n",
    "    print(\"2. Points cluster along the diagonal, indicating high autocorrelation.\")\n",
    "    print(\"3. The scatter pattern confirms the high Pearson correlation coefficient.\")\n",
    "\n",
    "def plot_autocorrelation(df):\n",
    "    \"\"\"Plot the autocorrelation function up to 100 lags.\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plot_acf(df['pm2.5'].dropna(), lags=100)\n",
    "    plt.title('Autocorrelation Function for PM2.5')\n",
    "    plt.xlabel('Lag')\n",
    "    plt.ylabel('Autocorrelation')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Observations from ACF plot:\")\n",
    "    print(\"1. The autocorrelation decreases as the lag increases.\")\n",
    "    print(\"2. Significant autocorrelation exists even at higher lag values.\")\n",
    "    print(\"3. The slow decay suggests the time series has strong persistence.\")\n",
    "    print(\"4. There may be seasonal patterns as indicated by periodic increases in correlation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_and_prepare_data('Pollution.csv')\n",
    "print(\"Data loaded successfully. First few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Part 1: Autocorrelation analysis\n",
    "print(\"\\n--- Part 1: Autocorrelation Analysis ---\")\n",
    "plot_time_series(df)\n",
    "df_clean, correlation = compute_lag_correlation(df)\n",
    "plot_lag_scatter(df_clean)\n",
    "plot_autocorrelation(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, train_size=0.65):\n",
    "    \"\"\"Split the data into training and testing sets.\"\"\"\n",
    "    train_size = int(len(df) * train_size)\n",
    "    train = df.iloc[:train_size]\n",
    "    test = df.iloc[train_size:]\n",
    "    return train, test\n",
    "\n",
    "def train_and_predict_ar(train, test, lag):\n",
    "    \"\"\"Train AR model and make predictions for the test set.\"\"\"\n",
    "    # Train the model\n",
    "    model = AR(train['pm2.5'], lags=lag).fit()\n",
    "    \n",
    "    # Get the coefficients\n",
    "    coef = model.params\n",
    "    print(f\"AR({lag}) Model Coefficients: {coef}\")\n",
    "    \n",
    "    # Prepare for prediction\n",
    "    history = list(train['pm2.5'].values)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = []\n",
    "    for t in range(len(test)):\n",
    "        lag_values = history[-lag:]\n",
    "        # Ensure we have enough lag values\n",
    "        if len(lag_values) < lag:\n",
    "            # Pad with zeros if needed\n",
    "            lag_values = [0] * (lag - len(lag_values)) + lag_values\n",
    "            \n",
    "        # Compute prediction using the AR formula\n",
    "        yhat = coef[0]\n",
    "        for i in range(lag):\n",
    "            if i < len(coef) - 1:  # Check if we have coefficient for this lag\n",
    "                yhat += coef[i+1] * lag_values[lag-i-1]\n",
    "        \n",
    "        predictions.append(yhat)\n",
    "        history.append(test['pm2.5'].iloc[t])\n",
    "    \n",
    "    return predictions, coef\n",
    "\n",
    "def plot_predictions(test, predictions, lag):\n",
    "    \"\"\"Create scatter and line plots for actual vs. predicted values.\"\"\"\n",
    "    # Scatter plot - convert to numpy arrays before plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(test['pm2.5'].to_numpy(), predictions, alpha=0.5)\n",
    "    plt.title(f'Actual vs. Predicted PM2.5 (Lag={lag})')\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Add a diagonal line for reference\n",
    "    min_val = min(min(test['pm2.5']), min(predictions))\n",
    "    max_val = max(max(test['pm2.5']), max(predictions))\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Line plot - convert to numpy arrays before plotting\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(test.index.to_numpy(), test['pm2.5'].to_numpy(), label='Actual')\n",
    "    plt.plot(test.index.to_numpy(), predictions, label='Predicted', alpha=0.7)\n",
    "    plt.title(f'Actual vs. Predicted PM2.5 Over Time (Lag={lag})')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('PM2.5')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(test, predictions):\n",
    "    \"\"\"Calculate RMSE and MAPE for model evaluation.\"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(test['pm2.5'], predictions))\n",
    "    mape = mean_absolute_percentage_error(test['pm2.5'], predictions) * 100\n",
    "    \n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAPE: {mape:.4f}%\")\n",
    "    \n",
    "    return rmse, mape\n",
    "\n",
    "def run_multiple_ar_models(train, test, lag_values):\n",
    "    \"\"\"Run AR models with different lag values and compare results.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for lag in lag_values:\n",
    "        print(f\"\\nRunning AR model with lag = {lag}\")\n",
    "        predictions, _ = train_and_predict_ar(train, test, lag)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        rmse, mape = evaluate_model(test, predictions)\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'lag': lag,\n",
    "            'rmse': rmse,\n",
    "            'mape': mape,\n",
    "            'predictions': predictions\n",
    "        })\n",
    "        \n",
    "        plot_predictions(test, predictions, lag)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_performance_metrics(results):\n",
    "    \"\"\"Plot RMSE and MAPE for different lag values.\"\"\"\n",
    "    lags = [r['lag'] for r in results]\n",
    "    rmse_values = [r['rmse'] for r in results]\n",
    "    mape_values = [r['mape'] for r in results]\n",
    "    \n",
    "    # RMSE plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(lags, rmse_values)\n",
    "    plt.title('RMSE vs. Lag Values')\n",
    "    plt.xlabel('Lag')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.xticks(lags)\n",
    "    plt.grid(True, axis='y')\n",
    "    plt.show()\n",
    "    \n",
    "    # MAPE plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(lags, mape_values)\n",
    "    plt.title('MAPE vs. Lag Values')\n",
    "    plt.xlabel('Lag')\n",
    "    plt.ylabel('MAPE (%)')\n",
    "    plt.xticks(lags)\n",
    "    plt.grid(True, axis='y')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Inference from RMSE and MAPE charts:\")\n",
    "    print(\"1. The error metrics tend to decrease as lag values increase initially.\")\n",
    "    print(\"2. After a certain point, adding more lags doesn't significantly improve performance.\")\n",
    "    print(\"3. There may be an optimal lag value that balances model complexity and accuracy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Autoregression models\n",
    "print(\"\\n--- Part 2: Autoregression Models ---\")\n",
    "train, test = split_data(df)\n",
    "print(f\"Training set size: {len(train)}\")\n",
    "print(f\"Testing set size: {len(test)}\")\n",
    "\n",
    "# Run models with different lag values\n",
    "lag_values = [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "results = run_multiple_ar_models(train, test, lag_values)\n",
    "plot_performance_metrics(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_lag(train):\n",
    "    \"\"\"Find optimal lag using the heuristic abs(AutoCorrelation) > 2/sqrt(T).\"\"\"\n",
    "    T = len(train)\n",
    "    threshold = 2 / np.sqrt(T)\n",
    "    \n",
    "    # Calculate autocorrelation for different lags\n",
    "    acf_values = []\n",
    "    max_lag = 100  # Maximum lag to consider\n",
    "    \n",
    "    for lag in range(1, max_lag + 1):\n",
    "        # Create lagged series\n",
    "        original = train['pm2.5'].iloc[lag:].values  # Skip first 'lag' values\n",
    "        lagged = train['pm2.5'].iloc[:-lag].values   # Skip last 'lag' values\n",
    "        \n",
    "        # Ensure both arrays have the same length\n",
    "        if len(original) > 0 and len(lagged) > 0:\n",
    "            corr, _ = pearsonr(original, lagged)\n",
    "            acf_values.append((lag, abs(corr)))\n",
    "    \n",
    "    # Find the maximum lag that satisfies the condition\n",
    "    optimal_lag = 1\n",
    "    for lag, acf in acf_values:\n",
    "        if acf > threshold:\n",
    "            optimal_lag = lag\n",
    "    \n",
    "    print(f\"Threshold for significance: {threshold:.4f}\")\n",
    "    print(f\"Optimal lag based on heuristic: {optimal_lag}\")\n",
    "    \n",
    "    return optimal_lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3: Optimal lag selection\n",
    "print(\"\\n--- Part 3: Optimal Lag Selection ---\")\n",
    "optimal_lag = find_optimal_lag(train)\n",
    "\n",
    "# Run model with optimal lag\n",
    "print(f\"\\nRunning AR model with optimal lag = {optimal_lag}\")\n",
    "predictions, _ = train_and_predict_ar(train, test, optimal_lag)\n",
    "plot_predictions(test, predictions, optimal_lag)\n",
    "rmse, mape = evaluate_model(test, predictions)\n",
    "\n",
    "# Compare with results from Part 2\n",
    "print(\"\\nComparison with models from Part 2:\")\n",
    "print(f\"Optimal lag model - RMSE: {rmse:.4f}, MAPE: {mape:.4f}%\")\n",
    "for result in results:\n",
    "    print(f\"Lag {result['lag']} model - RMSE: {result['rmse']:.4f}, MAPE: {result['mape']:.4f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
